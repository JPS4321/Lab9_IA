{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 9\n",
    "\n",
    "### Integrantes:\n",
    "\n",
    " - BRANDON JAVIER REYES MORALES\n",
    " - CARLOS ALBERTO VALLADARES GUERRA \n",
    " - JUAN PABLO SOLIS ALBIZUREZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 1: Teoria**\n",
    "\n",
    "1. Diga cuál es la diferencia entre Modelos de Markov y Hidden Markov Models\n",
    "- En los modelos de markov se representan sistemas donde el estado actual depende únicamente del estado anterior. Estos modelos asumen que todos los estados son observables. Por otro lado, los Hidden Markov Models suponen que los estados verdaderos del sistema son ocultos y no se pueden observar directamente. En su lugar, se observan señales o emisiones que dependen probabilísticamente de estos estados ocultos.\n",
    "\n",
    "2. Investigue qué son los factorial HMM (Hidden Markov Models)\n",
    "- Los factorial Hidden Markov Models  son una generalización de los Hidden Markov Models tradicionales. En lugar de tener una sola cadena de estados ocultos, los FHMM utilizan múltiples cadenas ocultas que evolucionan de forma paralela e independiente. Cada cadena representa una parte diferente del sistema oculto, y las observaciones se generan combinando la información de todas las cadenas. Esto permite modelar fenómenos más complejos, ya que se puede capturar la influencia simultánea de múltiples factores ocultos.\n",
    "\n",
    "3. Especifique en sus propias palabras el algoritmo Forward-Backward para HMM\n",
    "- El algoritmo Forward-Backward es una técnica utilizada en los HMM para calcular la probabilidad de que el sistema esté en un cierto estado en un momento dado, considerando toda la secuencia de observaciones. Este algoritmo tiene dos fases: la fase \"Forward\" calcula, hacia adelante en el tiempo, la probabilidad acumulada de haber alcanzado cada estado, dada la secuencia de observaciones hasta ese punto. La fase \"Backward\" hace el cálculo inverso: determina la probabilidad de observar la secuencia restante a partir de un estado específico, hacia atrás en el tiempo. \n",
    "\n",
    "4. En el algoritmo de Forward-Backward, ¿por qué es necesario el paso de Backward?\n",
    "- El paso de Backward es importante porque complementa la información histórica (Forward) con la información futura. Si solo se usa Forward, las decisiones se basarían únicamente en el pasado y no considerarían cómo las observaciones posteriores influyen en la estimación actual. Esto es importante en aplicaciones como el reconocimiento de voz, predicciones médicas, donde las evidencias futuras mejoran significativamente la inferencia de estados ocultos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secuencia Generada: ['Rainy', 'Rainy', 'Rainy', 'Sunny', 'Sunny']\n",
      "\n",
      "Probabilidades Forward:\n",
      "Tiempo 0: {'Sunny': 0.1, 'Rainy': 0.35}\n",
      "Tiempo 1: {'Sunny': 0.044000000000000004, 'Rainy': 0.16099999999999998}\n",
      "Tiempo 2: {'Sunny': 0.01992, 'Rainy': 0.07377999999999998}\n",
      "Tiempo 3: {'Sunny': 0.036358400000000006, 'Rainy': 0.014475599999999996}\n",
      "Tiempo 4: {'Sunny': 0.027901568000000005, 'Rainy': 0.004787112}\n",
      "\n",
      "Probabilidades Backward:\n",
      "Tiempo 0: {'Sunny': 0.04308720000000002, 'Rainy': 0.08108560000000002}\n",
      "Tiempo 1: {'Sunny': 0.12044000000000005, 'Rainy': 0.17012000000000005}\n",
      "Tiempo 2: {'Sunny': 0.4780000000000002, 'Rainy': 0.31400000000000006}\n",
      "Tiempo 3: {'Sunny': 0.7000000000000002, 'Rainy': 0.5}\n",
      "Tiempo 4: {'Sunny': 1, 'Rainy': 1}\n",
      "\n",
      "Probabilidades de Estado (Posteriores):\n",
      "Tiempo 0: {'Sunny': 0.13181076751952053, 'Rainy': 0.8681892324804794}\n",
      "Tiempo 1: {'Sunny': 0.1621160597491242, 'Rainy': 0.8378839402508756}\n",
      "Tiempo 2: {'Sunny': 0.29128615777694306, 'Rainy': 0.708713842223057}\n",
      "Tiempo 3: {'Sunny': 0.7785839012159562, 'Rainy': 0.2214160987840438}\n",
      "Tiempo 4: {'Sunny': 0.8535544414763766, 'Rainy': 0.14644555852362343}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class HMM:\n",
    "    def __init__(self, states, observations, initial_prob, transition_prob, emission_prob):\n",
    "        self.states = states\n",
    "        self.observations = observations\n",
    "        self.initial_prob = initial_prob\n",
    "        self.transition_prob = transition_prob\n",
    "        self.emission_prob = emission_prob\n",
    "\n",
    "    def generate_sequence(self, length):\n",
    "        sequence = []\n",
    "        current_state = random.choices(self.states, weights=[self.initial_prob[s] for s in self.states])[0]\n",
    "        \n",
    "        for _ in range(length):\n",
    "            obs = random.choices(self.observations, weights=[self.emission_prob[current_state][o] for o in self.observations])[0]\n",
    "            sequence.append(obs)\n",
    "            current_state = random.choices(self.states, weights=[self.transition_prob[current_state][s] for s in self.states])[0]\n",
    "        \n",
    "        return sequence\n",
    "\n",
    "    def forward(self, obs_sequence):\n",
    "        forward_probs = [{}]\n",
    "        for state in self.states:\n",
    "            forward_probs[0][state] = self.initial_prob[state] * self.emission_prob[state][obs_sequence[0]]\n",
    "\n",
    "        for t in range(1, len(obs_sequence)):\n",
    "            forward_probs.append({})\n",
    "            for curr_state in self.states:\n",
    "                prob_sum = sum(\n",
    "                    forward_probs[t-1][prev_state] * self.transition_prob[prev_state][curr_state]\n",
    "                    for prev_state in self.states\n",
    "                )\n",
    "                forward_probs[t][curr_state] = prob_sum * self.emission_prob[curr_state][obs_sequence[t]]\n",
    "        \n",
    "        return forward_probs\n",
    "\n",
    "    def backward(self, obs_sequence):\n",
    "        backward_probs = [{} for _ in range(len(obs_sequence))]\n",
    "        for state in self.states:\n",
    "            backward_probs[-1][state] = 1\n",
    "\n",
    "        for t in reversed(range(len(obs_sequence) - 1)):\n",
    "            for curr_state in self.states:\n",
    "                backward_probs[t][curr_state] = sum(\n",
    "                    self.transition_prob[curr_state][next_state] *\n",
    "                    self.emission_prob[next_state][obs_sequence[t+1]] *\n",
    "                    backward_probs[t+1][next_state]\n",
    "                    for next_state in self.states\n",
    "                )\n",
    "        \n",
    "        return backward_probs\n",
    "\n",
    "    def compute_state_probabilities(self, obs_sequence):\n",
    "        forward_probs = self.forward(obs_sequence)\n",
    "        backward_probs = self.backward(obs_sequence)\n",
    "\n",
    "        state_probs = [{} for _ in range(len(obs_sequence))]\n",
    "\n",
    "        for t in range(len(obs_sequence)):\n",
    "            total_prob = sum(\n",
    "                forward_probs[t][state] * backward_probs[t][state]\n",
    "                for state in self.states\n",
    "            )\n",
    "            for state in self.states:\n",
    "                state_probs[t][state] = (forward_probs[t][state] * backward_probs[t][state]) / total_prob\n",
    "        \n",
    "        return state_probs\n",
    "\n",
    "\n",
    "states = ['Sunny', 'Rainy']\n",
    "observations = ['Sunny', 'Rainy']\n",
    "\n",
    "initial_prob = {'Sunny': 0.5, 'Rainy': 0.5}\n",
    "\n",
    "transition_prob = {\n",
    "    'Sunny': {'Sunny': 0.8, 'Rainy': 0.2},\n",
    "    'Rainy': {'Sunny': 0.4, 'Rainy': 0.6}\n",
    "}\n",
    "\n",
    "emission_prob = {\n",
    "    'Sunny': {'Sunny': 0.8, 'Rainy': 0.2},\n",
    "    'Rainy': {'Sunny': 0.3, 'Rainy': 0.7}\n",
    "}\n",
    "\n",
    "hmm = HMM(states, observations, initial_prob, transition_prob, emission_prob)\n",
    "\n",
    "# --- Impresiones usando print(\"texto\" + str(variable)) ---\n",
    "obs_sequence = hmm.generate_sequence(5)\n",
    "print(\"Secuencia Generada: \" + str(obs_sequence))\n",
    "\n",
    "forward_probs = hmm.forward(obs_sequence)\n",
    "print(\"\\nProbabilidades Forward:\")\n",
    "for t, probs in enumerate(forward_probs):\n",
    "    print(\"Tiempo \" + str(t) + \": \" + str(probs))\n",
    "\n",
    "backward_probs = hmm.backward(obs_sequence)\n",
    "print(\"\\nProbabilidades Backward:\")\n",
    "for t, probs in enumerate(backward_probs):\n",
    "    print(\"Tiempo \" + str(t) + \": \" + str(probs))\n",
    "\n",
    "state_probs = hmm.compute_state_probabilities(obs_sequence)\n",
    "print(\"\\nProbabilidades de Estado (Posteriores):\")\n",
    "for t, probs in enumerate(state_probs):\n",
    "    print(\"Tiempo \" + str(t) + \": \" + str(probs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras aplicar el algoritmo Forward-Backward sobre la secuencia generada ['Rainy', 'Rainy', 'Sunny', 'Rainy', 'Sunny'], se observaron las probabilidades posteriores de estar en cada estado en cada tiempo. Inicialmente, se tiene alta probabilidad de que el estado real haya sido \"Rainy\", dado que las primeras observaciones fueron lluviosas. Conforme avanzan los días y cambian las observaciones, las probabilidades reflejan que es más probable que el estado sea \"Sunny\" en los días donde se observa sol. En general, las probabilidades calculadas permiten inferir el estado real oculto a partir de las observaciones visibles, integrando la información tanto pasada como futura.\n",
    "\n",
    "| Tiempo | Observación | Estado más probable | Probabilidad |\n",
    "|:------:|:-----------:|:-------------------:|:------------:|\n",
    "|   0    | Rainy       | Rainy                | 84.3%        |\n",
    "|   1    | Rainy       | Rainy                | 74.6%        |\n",
    "|   2    | Sunny       | Sunny                | 63.3%        |\n",
    "|   3    | Rainy       | Rainy                | 53.3%        |\n",
    "|   4    | Sunny       | Sunny                | 76.8%        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referencias: \n",
    "\n",
    " -  Rabiner, L. R. (1989).A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition.Disponible en: https://www.cs.ubc.ca/~murphyk/Bayes/rabiner.pdf​\n",
    "\n",
    " -  Ghahramani, Z., & Jordan, M. I. (1997). Factorial Hidden Markov Models.Disponible en: https://mlg.eng.cam.ac.uk/zoubin/papers/fhmmML.pdf​\n",
    "\n",
    " -  Durbin, R., Eddy, S. R., Krogh, A., & Mitchison, G. J. (1998). Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
